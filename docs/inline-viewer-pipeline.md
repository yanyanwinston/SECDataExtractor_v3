# Inline iXBRL to Viewer Pipeline

This note explains how SECDataExtractor turns an Inline XBRL filing into the viewer
JSON that powers the presentation-first parser. Share it with new contributors when
they need to understand why we invoke Arelle, what artifacts appear in `temp/`, and
why the companion taxonomy files matter.

## Key Artifacts
- **Inline filing** – the EDGAR download we ingest, e.g.
  `downloads/TSLA/10-K_2020-12-31/tsla-10k_20201231.htm`. It mixes regular HTML with
  `ix:` tags and references the company’s schema and linkbases via `<link:schemaRef>`.
- **Viewer bundle** – generated by Arelle’s iXBRLViewerPlugin, e.g.
  `temp/arelle/arelle_output_293/ixbrl-viewer.htm` plus `ixbrlviewer.js`. The HTML
  contains the consolidated JSON payload (`sourceReports`, `facts`, `concepts`,
  `rels.pres`) that our parser consumes.
- **MetaLinks.json (optional)** – extra role metadata that Arelle writes when
  available. Our extractor first looks for the version Arelle just produced, then
  falls back to any MetaLinks bundled in the EDGAR download. The pipeline still
  works without it; we just lose curated role grouping and label overrides.

## How the Pipeline Uses Them
1. `render_viewer_to_xlsx.py` hands the inline filing to
   `src/processor/arelle_processor.py`, which shells out to:
   ```bash
   python -m arelle.CntlrCmdLine --plugins iXBRLViewerPlugin \
     --file <inline filing> --save-viewer <temp>/ixbrl-viewer.htm
   ```
2. Arelle resolves every schema (`*.xsd`) and linkbase (`*_pre.xml`, `*_lab.xml`,
   `*_cal.xml`, etc.) referenced by `<link:schemaRef>` inside the inline HTML. Those
   files live beside the filing in `downloads/...`, so we do not need to enumerate
   them manually.
3. `ViewerDataExtractor` (`src/processor/json_extractor.py`) opens the
   `ixbrl-viewer.htm`, extracts the embedded JSON, and (if present) merges
   `MetaLinks.json` so we get `role_map` and `concept_labels`. The lookup order is:
   - the same directory as the freshly written viewer HTML;
   - its parent (the iXBRL plugin occasionally places MetaLinks one level up);
   - any explicit candidates we pass in—namely the `MetaLinks.json` that shipped
     with the EDGAR download.
   That ordering keeps our renderer aligned with the latest Arelle output while
   remaining compatible with filings that only provide the upstream MetaLinks.
4. The parser (`src/processor/presentation_parser.py` and
   `src/processor/data_parser.py`) builds statement trees from that JSON, matches
   facts, and hands structured data to `ExcelGenerator`.

MetaLinks enriches labels and `groupType` hints, but it is optional: the viewer JSON
already contains `roleDefs`, `rels.pres`, and `concepts`, so we fall back to those when
MetaLinks is absent.

## What Happens If Taxonomy Files Are Missing?
We verified this with the TSLA 2020 10-K.

```bash
mkdir -p temp/inline_only
cp downloads/TSLA/10-K_2020-12-31/tsla-10k_20201231.htm temp/inline_only/
python -m arelle.CntlrCmdLine --plugins iXBRLViewerPlugin \
  --file temp/inline_only/tsla-10k_20201231.htm \
  --save-viewer temp/inline_only/only_viewer.htm
```

The command succeeds, but the log is full of warnings:
```
[IOerror] Could not load file from local filesystem. file: .../tsla-20201231.xsd
[ix11.12.1.2:missingReferences] Instance fact missing schema definition: us-gaap:Revenues...
```
Inspecting the viewer JSON confirms the damage:
- `facts`: 2,093 entries (the inline facts themselves)
- `concepts`: **0 entries**
- `rels.pres`: **0 presentation roles**

Without the companion taxonomy files, Arelle cannot populate concept definitions or
presentation relationships, so our presentation-first parser has nothing to work with.
In contrast, running the same command against the full download directory produces a
viewer with 1,101 concepts and 131 presentation roles—exactly what the pipeline needs.

## Takeaways for Contributors
- Always keep the filing directory intact (`downloads/<ticker>/...`); do not strip out
  the `*.xsd`, `*_pre.xml`, `*_lab.xml`, or other linkbases when testing.
- When debugging viewer extraction, look under the temp directory you passed to the
  CLI (e.g. `temp/arelle/arelle_output_<hash>/`). Add `--keep-temp` if you want those
  artifacts to survive cleanup.
- Missing `MetaLinks.json` is fine; missing linkbases is not. If you see
  `missingReferences` warnings, verify that the schema/linkbase files sit next to the
  inline HTML and that you ran Arelle from a location that can reach them.
- If you ever need to regenerate the viewer manually, use the same command the CLI
  issues (shown above) so you work with the exact payload our code expects.

Keep this note nearby when onboarding new engineers—they can reproduce the experiment
and immediately see why the viewer step and the supplemental files are required.
